{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-01-18T15:11:21.494381Z",
     "iopub.status.busy": "2026-01-18T15:11:21.494103Z",
     "iopub.status.idle": "2026-01-18T15:11:21.500414Z",
     "shell.execute_reply": "2026-01-18T15:11:21.499639Z",
     "shell.execute_reply.started": "2026-01-18T15:11:21.494359Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as f\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from torch.nn.parameter import Parameter\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics import classification_report, confusion_matrix, cohen_kappa_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T15:11:24.410330Z",
     "iopub.status.busy": "2026-01-18T15:11:24.410046Z",
     "iopub.status.idle": "2026-01-18T15:11:24.428204Z",
     "shell.execute_reply": "2026-01-18T15:11:24.427633Z",
     "shell.execute_reply.started": "2026-01-18T15:11:24.410305Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data ready training on 3112 images\n"
     ]
    }
   ],
   "source": [
    "# data loading and splitting\n",
    "path_2019_dir = '/kaggle/input/aptos2019-blindness-detection/'\n",
    "df_2019 = pd.read_csv(os.path.join(path_2019_dir, 'train.csv'))\n",
    "\n",
    "df_2019['path'] = df_2019['id_code'].apply(lambda x: os.path.join(path_2019_dir, 'train_images', f'{x}.png'))\n",
    "df_2019['target'] = df_2019['diagnosis']\n",
    "\n",
    "train_df, val_df = train_test_split(df_2019, test_size=0.15, stratify=df_2019['target'], random_state=42)\n",
    "print(f\"data ready training on {len(train_df)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T15:11:26.261869Z",
     "iopub.status.busy": "2026-01-18T15:11:26.261556Z",
     "iopub.status.idle": "2026-01-18T15:11:26.272306Z",
     "shell.execute_reply": "2026-01-18T15:11:26.271514Z",
     "shell.execute_reply.started": "2026-01-18T15:11:26.261846Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "img_size = 300\n",
    "\n",
    "def ben_graham_processing(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresh = cv2.threshold(gray, 10, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if contours:\n",
    "        x, y, w, h = cv2.boundingRect(max(contours, key=cv2.contourArea))\n",
    "        image = image[y:y+h, x:x+w]\n",
    "    image = cv2.resize(image, (img_size, img_size))\n",
    "    image = cv2.addWeighted(image, 4, cv2.GaussianBlur(image, (0,0), 10), -4, 128)\n",
    "    mask = np.zeros((img_size, img_size), np.uint8)\n",
    "    cv2.circle(mask, (img_size//2, img_size//2), img_size//2, 1, thickness=-1)\n",
    "    return cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "class drdataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.df = dataframe\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        img = cv2.imread(self.df.iloc[idx]['path'])\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = ben_graham_processing(img)\n",
    "        label = torch.tensor(self.df.iloc[idx]['target'], dtype=torch.float32)\n",
    "        if self.transform: img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "train_aug = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_aug = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_loader = DataLoader(drdataset(train_df, train_aug), batch_size=16, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(drdataset(val_df, val_aug), batch_size=16, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T15:12:24.994442Z",
     "iopub.status.busy": "2026-01-18T15:12:24.993685Z",
     "iopub.status.idle": "2026-01-18T15:12:25.249182Z",
     "shell.execute_reply": "2026-01-18T15:12:25.248388Z",
     "shell.execute_reply.started": "2026-01-18T15:12:24.994406Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# stable gem pooling and model\n",
    "class gem(nn.Module):\n",
    "    def __init__(self, p=3, eps=1e-6):\n",
    "        super(gem, self).__init__()\n",
    "        self.p = p # fixed p instead of parameter to stop inplace errors\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        # using a more stable sequence of operations for autograd\n",
    "        x = x.clamp(min=self.eps)\n",
    "        x = x ** self.p\n",
    "        x = f.avg_pool2d(x, (x.size(-2), x.size(-1)))\n",
    "        x = x ** (1.0 / self.p)\n",
    "        return x\n",
    "\n",
    "# re-initialize the model\n",
    "model = models.efficientnet_b3(weights='DEFAULT')\n",
    "model.avgpool = gem(p=3) # set a fixed p=3\n",
    "in_features = model.classifier[1].in_features\n",
    "model.classifier[1] = nn.Linear(in_features, 1)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.HuberLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T15:12:28.803513Z",
     "iopub.status.busy": "2026-01-18T15:12:28.802758Z",
     "iopub.status.idle": "2026-01-18T16:11:23.815501Z",
     "shell.execute_reply": "2026-01-18T16:11:23.814738Z",
     "shell.execute_reply.started": "2026-01-18T15:12:28.803482Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# training (limited epochs to prevent overfitting)\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for images, labels in tqdm(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device).view(-1, 1)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T16:27:27.976244Z",
     "iopub.status.busy": "2026-01-18T16:27:27.975946Z",
     "iopub.status.idle": "2026-01-18T16:27:28.069587Z",
     "shell.execute_reply": "2026-01-18T16:27:28.068980Z",
     "shell.execute_reply.started": "2026-01-18T16:27:27.976221Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved successfully to /kaggle/working/best_model.pth\n"
     ]
    }
   ],
   "source": [
    "# save model after all epochs\n",
    "import torch\n",
    "try:\n",
    "    torch.save(model.state_dict(), 'best_model.pth')\n",
    "    print(\"saved successfully to /kaggle/working/best_model.pth\")\n",
    "except Exception as e:\n",
    "    print(f\"error saving: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stability check\n",
    "def get_stable_prediction(model, img_tensor):\n",
    "    model.eval()\n",
    "    versions = [img_tensor, torch.flip(img_tensor, [3]), torch.flip(img_tensor, [2]), torch.rot90(img_tensor, 1, [2, 3])]\n",
    "    results = []\n",
    "    with torch.no_grad():\n",
    "        for v in versions:\n",
    "            results.append(model(v.to(device)).item())\n",
    "    mean_val = np.mean(results)\n",
    "    stability = 1.0 - np.std(results)\n",
    "    verdict = \"stable\" if stability > 0.85 else \"unstable\"\n",
    "    return mean_val, stability, verdict\n",
    "\n",
    "img_tensor, _ = next(iter(val_loader))\n",
    "val, stab, msg = get_stable_prediction(model, img_tensor[0].unsqueeze(0))\n",
    "print(f\"prediction: {val:.2f} | stability: {stab:.4f} | status: {msg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T16:41:01.955314Z",
     "iopub.status.busy": "2026-01-18T16:41:01.955031Z",
     "iopub.status.idle": "2026-01-18T16:41:02.256262Z",
     "shell.execute_reply": "2026-01-18T16:41:02.255612Z",
     "shell.execute_reply.started": "2026-01-18T16:41:01.955291Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimized thresholds: [0.76508932 1.47002369 2.67058553 2.94852521]\n",
      "--- final results ---\n",
      "new accuracy: 0.8055\n",
      "new kappa: 0.8865\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       0-Normal       0.93      0.99      0.96       271\n",
      "         1-Mild       0.54      0.46      0.50        56\n",
      "     2-Moderate       0.73      0.81      0.77       150\n",
      "       3-Severe       0.39      0.24      0.30        29\n",
      "4-Proliferative       0.68      0.48      0.56        44\n",
      "\n",
      "       accuracy                           0.81       550\n",
      "      macro avg       0.65      0.60      0.62       550\n",
      "   weighted avg       0.79      0.81      0.79       550\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# accuracy & kappa optimizer\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score\n",
    "\n",
    "def optimize_metrics(coeffs, raw_preds, targets):\n",
    "    # force thresholds to stay in order for np.digitize\n",
    "    if not np.all(np.diff(coeffs) > 0):\n",
    "        return 10.0 # return a high penalty if thresholds get out of order\n",
    "    \n",
    "    preds = np.digitize(raw_preds, coeffs)\n",
    "    \n",
    "    # trying balanceed accuracy and kappa weights\n",
    "    acc = accuracy_score(targets, preds)\n",
    "    kap = cohen_kappa_score(targets, preds, weights='quadratic')\n",
    "    \n",
    "    # we want the highest sum, so we return negative sum for the minimizer\n",
    "    return -(0.5 * acc + 0.5 * kap)\n",
    "\n",
    "# thresholds (inspired by the winning solution)\n",
    "initial_thresholds = [0.7, 1.5, 2.5, 3.5]\n",
    "\n",
    "# search for best thresholds for our specific validation set\n",
    "result = minimize(optimize_metrics, initial_thresholds, \n",
    "                  args=(raw_preds, labels), \n",
    "                  method='nelder-mead',\n",
    "                  options={'xatol': 1e-4})\n",
    "\n",
    "best_thresholds = np.sort(result.x)\n",
    "final_optimized_preds = np.digitize(raw_preds, best_thresholds)\n",
    "\n",
    "print(f\"optimized thresholds: {best_thresholds}\")\n",
    "print(f\"--- final results ---\")\n",
    "print(f\"new accuracy: {accuracy_score(labels, final_optimized_preds):.4f}\")\n",
    "print(f\"new kappa: {cohen_kappa_score(labels, final_optimized_preds, weights='quadratic'):.4f}\")\n",
    "print(classification_report(labels, final_optimized_preds, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experimenting with tta\n",
    "def get_preds_with_tta(model, loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader):\n",
    "            images = images.to(device)\n",
    "            \n",
    "            # original\n",
    "            out1 = model(images)\n",
    "            # horizontal flip\n",
    "            out2 = model(torch.flip(images, dims=[3]))\n",
    "            # vertical flip\n",
    "            out3 = model(torch.flip(images, dims=[2]))\n",
    "            \n",
    "            \n",
    "            avg_out = (out1 + out2 + out3) / 3.0\n",
    "            \n",
    "            all_preds.extend(avg_out.cpu().numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "            \n",
    "    return np.array(all_preds).flatten(), np.array(all_labels)\n",
    "\n",
    "# get the new \"stabilized\" predictions\n",
    "raw_preds_tta, labels = get_preds_with_tta(model, val_loader)\n",
    "\n",
    "# need to run the optimizer again with tta preds"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 46661,
     "sourceId": 4104,
     "sourceType": "competition"
    },
    {
     "databundleVersionId": 875431,
     "sourceId": 14774,
     "sourceType": "competition"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 563315,
     "modelInstanceId": 550689,
     "sourceId": 723696,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31259,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
